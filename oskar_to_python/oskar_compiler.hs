import Data.Time
import Text.Read
import System.Environment

main = do
  args <- getArgs
  timestamp_io <- getZonedTime
  case args of
    [inFile, outFile] -> do
      contents_io <- readFile inFile
      writeFiles timestamp_io contents_io outFile
    _ -> do
      contents_io <- readFile "../oskar_src_files/input.osk"
      writeFiles timestamp_io contents_io "../python_to_openscad/output.py"

writeFiles timestamp contents outFile =
  let tokens      = tokenizeString contents
      syntax_tree = parseSyntaxTree tokens

      header = "\"\"\"\n\n" ++
              "Python Generated by the OSKAR Compiler v2.3 at\n" ++
              show timestamp ++ "\n\n" ++
              "Compiler written by Bryce Summers\n" ++
              "Please see https://github.com/Bryce-Summers/OSKAR\n\n" ++
              "\"\"\"\n"

      output      = generatePython syntax_tree header
  in do
    writeFile "tokens.txt" (unlines (tokens_to_debug_words tokens))
    writeFile outFile (unlines output)

--This seems kind of useless to me.
--Removes all junk, such as new line characters, places a ; at the end of every line.
lineReconstructor :: [Char] -> [Char]
lineReconstructor [] = []
lineReconstructor ('\n':rest) = ';' : lineReconstructor rest
lineReconstructor (a:rest) = a : lineReconstructor rest

-- Splits up an input string into atomic syntactic parts.
-- Input String, (reading_comment, reading_token)
tokenizeString :: String -> [[String]]
tokenizeString input = tokenize input (False, False) ("[File Name]", 1, 1)

 -- string to be tokenized, (currently reading a comment, currently reading a token),
 -- (Filename, Line number, Column number)
tokenize :: String -> (Bool, Bool) -> (String, Int, Int) -> [[String]]
-- base case, return the empty end of list.
tokenize [] (_, True)  _  = []:[]
tokenize [] (_, False) _  = []
-- If we see a new line character and we have been reading a token, then we conclude it with an end of list. (End of String.)
tokenize ('\n':xs) (_, True) (f, line, _)  = [] : tokenize xs (False, False) (f, line + 1, 1) -- New Line.
-- If we are not reading a token and come across a new line, then we just ignore it.
tokenize ('\n':xs) (_, False) (f, line, _) = tokenize xs (False, False) (f, line + 1, 1)       -- New Line.

{-|
--- The following lines of code implement tokenization that generates comment tokens.
-- For comments, we just continue to push all characters into a list.
tokenize (x:xs) (True, _)     = let rest_of_comment:rest_of_tokens = tokenize xs (True, True)
                              in (x:rest_of_comment):rest_of_tokens
-- Start of a commment, End of token.
tokenize ('#':xs) (_, True)   = let rest_of_comment:rest_of_tokens = tokenize xs (True, True)
                              in []:('#':rest_of_comment):rest_of_tokens
-- Start of a comment, without ending a token.
tokenize ('#':xs) (_, False)  = let rest_of_comment:rest_of_tokens = tokenize xs (True, True)
                              in ('#':rest_of_comment):rest_of_tokens
-}

-- The Following lines implement tokenization that completely ignores comments.
-- FIXME: Perhaps I should make comment peeling its own function.
tokenize (x:xs)   (True, _)  (f, line, col) = tokenize xs (True, False)        (f, line, col + 1)
tokenize ('#':xs) (_, True)  (f, line, col) = [] : (tokenize xs (True, False)) (f, line, col + 1)
tokenize ('#':xs) (_, False) (f, line, col) = tokenize xs (True, False)        (f, line, col + 1)


-- For Simple operators and syntactic symbols, we can directly parse them to tokens.
tokenize (':':':':':':xs) (_, t) (f,l,c)
    | t == False = symbol : tokenize xs (False, False)      (f, l, c + 1)
    | t == True  = [] : symbol : tokenize xs (False, False) (f, l, c + 1)
    where symbol = ":::":f:(show l):(show c):[]
tokenize (':':':':xs) (_, t) (f,l,c)
    | t == False = symbol : tokenize xs (False, False)      (f, l, c + 1)
    | t == True  = [] : symbol : tokenize xs (False, False) (f, l, c + 1)
    where symbol = "::":f:(show l):(show c):[]
tokenize (':':xs) (_, t) (f,l,c)
    | t == False = symbol : tokenize xs (False, False)      (f, l, c + 1)
    | t == True  = [] : symbol : tokenize xs (False, False) (f, l, c + 1)
    where symbol = ":":f:(show l):(show c):[]
tokenize ('<':'<':'<':xs) (_, t) (f,l,c)
    | t == False = symbol : tokenize xs (False, False)      (f, l, c + 1)
    | t == True  = [] : symbol : tokenize xs (False, False) (f, l, c + 1)
    where symbol = "<<<":f:(show l):(show c):[]
tokenize ('<':'<':xs) (_, t) (f,l,c)
    | t == False = symbol : tokenize xs (False, False)      (f, l, c + 1)
    | t == True  = [] : symbol : tokenize xs (False, False) (f, l, c + 1)
    where symbol = "<<":f:(show l):(show c):[]
tokenize (',':xs) (_, t) (f,l,c)
    | t == False = symbol : tokenize xs (False, False)      (f, l, c + 1)
    | t == True  = [] : symbol : tokenize xs (False, False) (f, l, c + 1)
    where symbol = ",":f:(show l):(show c):[]
tokenize ('=':xs) (_, t) (f,l,c)
    | t == False = symbol : tokenize xs (False, False)      (f, l, c + 1)
    | t == True  = [] : symbol : tokenize xs (False, False) (f, l, c + 1)
    where symbol = "=":f:(show l):(show c):[]
tokenize ('*':xs) (_, t) (f,l,c)
    | t == False = symbol : tokenize xs (False, False)      (f, l, c + 1)
    | t == True  = [] : symbol : tokenize xs (False, False) (f, l, c + 1)
    where symbol = "*":f:(show l):(show c):[]
tokenize ('/':xs) (_, t) (f,l,c)
    | t == False = symbol : tokenize xs (False, False)      (f, l, c + 1)
    | t == True  = [] : symbol : tokenize xs (False, False) (f, l, c + 1)
    where symbol = "/":f:(show l):(show c):[]
tokenize ('+':xs) (_, t) (f,l,c)
    | t == False = symbol : tokenize xs (False, False)      (f, l, c + 1)
    | t == True  = [] : symbol : tokenize xs (False, False) (f, l, c + 1)
    where symbol = "+":f:(show l):(show c):[]
{-
tokenize ('-':xs) (_, t)         | t == False = symbol : tokenize xs (False, False)
                                 | t == True  = [] : symbol : tokenize xs (False, False)
                                 where symbol = "-"
-}
tokenize ('(':xs) (_, t) (f,l,c)
    | t == False = symbol : tokenize xs (False, False)      (f, l, c + 1)
    | t == True  = [] : symbol : tokenize xs (False, False) (f, l, c + 1)
    where symbol = "(":f:(show l):(show c):[]
tokenize (')':xs) (_, t) (f,l,c)
    | t == False = symbol : tokenize xs (False, False)      (f, l, c + 1)
    | t == True  = [] : symbol : tokenize xs (False, False) (f, l, c + 1)
    where symbol = ")":f:(show l):(show c):[]
tokenize ('[':xs) (_, t) (f,l,c)
    | t == False = symbol : tokenize xs (False, False)      (f, l, c + 1)
    | t == True  = [] : symbol : tokenize xs (False, False) (f, l, c + 1)
    where symbol = "[":f:(show l):(show c):[]
tokenize (']':xs) (_, t) (f,l,c)
    | t == False = symbol : tokenize xs (False, False)      (f, l, c + 1)
    | t == True  = [] : symbol : tokenize xs (False, False) (f, l, c + 1)
    where symbol = "]":f:(show l):(show c):[]
tokenize ('{':xs) (_, t) (f,l,c)
    | t == False = symbol : tokenize xs (False, False)      (f, l, c + 1)
    | t == True  = [] : symbol : tokenize xs (False, False) (f, l, c + 1)
    where symbol = "{":f:(show l):(show c):[]
tokenize ('}':xs) (_, t) (f,l,c)
    | t == False = symbol : tokenize xs (False, False)      (f, l, c + 1)
    | t == True  = [] : symbol : tokenize xs (False, False) (f, l, c + 1)
    where symbol = "}":f:(show l):(show c):[]
tokenize ('@':xs) (_, t) (f,l,c)
    | t == False = symbol : tokenize xs (False, False)      (f, l, c + 1)
    | t == True  = [] : symbol : tokenize xs (False, False) (f, l, c + 1)
    where symbol = "@":f:(show l):(show c):[]


-- Substitute $ signs for the prefix "Global_"
-- We need to subtract enough letters for the Global_ to ensure proper column numbers after this point.
tokenize ('$': xs) (_,t) (f,l,c) = tokenize ('G':'l':'o':'b':'a':'l':'_':xs)(False, t) (f, l, c - 1)

-- End tokens with spaces, but otherwise ignore them.
tokenize (' ':xs) (_, True)  (f,l,c) = [] : tokenize xs (False, False) (f, l, c + 1)
tokenize (' ':xs) (_, False) (f,l,c) = tokenize xs (False, False)      (f, l, c + 1)

-- Everything else are names.
tokenize (x:xs) (False, _) (f,l,c) = let token:rest_of_tokens = tokenize xs (False, True) (f, l, c + 1)
                                         line   = show l
                                         column = show c
                                     in case token of
                                         name:rest_of_token ->
                                             ((x:name):f:(show l):(show c):[]):rest_of_tokens
                                         [] ->
                                             ((x:[]):f:(show l):(show c):[]):rest_of_tokens


-- Here we define the data type for the abstract syntax tree and a healthy collection of lower level types.
data AST = AST {ast_pictures :: [Picture]
               ,ast_drawings :: [DrawCommand]
               ,ast_functions:: [Function]
               } --deriving (Show, Read, Eq)

data Picture =  Picture { picture_name       :: String
                        ,picture_arguments  :: [String]
                        ,picture_basis      :: String      -- The Name of a lower level Picture definition that will be used to form this picture.
                        ,picture_transforms :: [Transform] -- The transforms in order that will be applied to the basis picture for each iteration.
                        ,picture_iterations :: Iteration   -- An iteration object to control the looping.
                       } |
                Direct_Picture(String, String)
                -- A picture may be directly defined in terms of an expression string, for instance with


                --Direct_Picture { direct_picture_name :: String
                --        ,direct_picture_expression :: Expression
                --       }
                
                                          -- cosine  <<  funplot(myTY1)
                                          -- It will be represented by (name, expression)

data Transform = Transform { transform_species :: Transform_Species
                            ,transform_x :: String
                            ,transform_y :: String
                            ,transform_z :: String
                           } -- deriving (Show)

data Transform_Species = Translate | Scale | Rotate --deriving (Show, Eq)

-- Single Valued function (name, arguments, expression) or
-- 3-valued vector (name, arguments, x_expression, y_expression, z_expression)
-- Type is based on the cardinalitty of the expression list.
data Function = Function { function_name        :: String   -- Name of function.
                         , function_arguments   :: [String] -- symbolic variable names for the arguments that will be passed in.
                         , function_expressions :: [Expression] -- A vector of expressions. Single valued functions will have lists of length 1.
                         , function_type        :: Function_Type
                         } deriving (Show)

data Function_Type = Scalar | Vector

-- (x, y, z) FIXME: Rewrite Transform in terms of Expressions.
-- This is sufficiently general enough that I can continue to use this if we go to higher dimensions.
type Expression = String

-- We use Strings for everything to ensure that variable names may be accomodated.
data Iteration = Iteration { iteration_variable :: String -- The iteration variable. e.g. 'i', 'j', etc.
                            ,iteration_begin :: String    -- The iteration this variable will start at.
                            ,iteration_end   :: String    -- The iteration this variable will end before.
                           }                              -- for variable = begin; variable < end; variable++

data DrawCommand =  DrawCommand { drawCommand_iterations  :: Iteration
                                 , drawCommand_pictures   :: [String]
                                }

-- Parse States used to communicate up and down recursive parse function calls.
-- Name refers to definition variable names. Left_Paren -> '(', Left_Curly -> '{', Done indicates a state of normalcy.
data ParseState = Name | Left_Paren| Left_Curly | Done deriving (Eq)  


-- Token String, Filename String, Line number, Column number.
-- TokenString:Filename:LineNumber:Column number.
type Token  = [String]
type Tokens = [Token]


-- Show converts the type to a string.
-- read constructs the type from a string.

instance Show Transform_Species where
    show Translate = "translation"
    show Scale     = "scaling"
    show Rotate    = "rotation"

instance Show Function_Type where
    show Scalar    = "scalar"
    show Vector    = "vector"

-- Converts a list of tokens into an abstract syntax tree.
parseSyntaxTree :: [[String]] -> AST
parseSyntaxTree tokens =
    _parseSyntaxTree tokens [] [] []

-- tokens -> Pictures accumulator -> DrawCommands accumulator -> Function Accumulator -> output
_parseSyntaxTree :: [[String]] -> [Picture] -> [DrawCommand] -> [Function] -> AST
-- Handle Empty List.
_parseSyntaxTree [] pics draws funcs = AST {ast_pictures=pics, ast_drawings=draws, ast_functions=funcs}
-- Handle Picture definition.
_parseSyntaxTree ((name:_):(("<<":_):rest)) pictures drawCommands funcs = 
    let (picture, rest_of_tokens) = parsePicture name [] rest
    in  _parseSyntaxTree rest_of_tokens (picture ++ pictures) drawCommands funcs

--_parseSyntaxTree (tokens@((name:_):("<<<":_):rest)) pictures drawCommands funcs = 
--    let (picture, rest_of_tokens) = parsePicture tokens
--    in  _parseSyntaxTree rest_of_tokens (picture ++ pictures) drawCommands funcs
-- Picture function.

-- Functions and picture functions. We recognize them by their "(" arguments"
_parseSyntaxTree ((name:_):("(":rp):rest) pictures drawCommands funcs =
    let (arguments, (def_symbol:f:l:c:[]):rest1) = parseBraket (("(":rp):rest) "(" ")"
    in case def_symbol of
         -- Picture Function / Picture.
        "<<<" ->
            --error ("Picture functions are not yet supported: \"" ++ def_symbol ++"\" at " ++ debug f l c ++ " Maybe it is misplaced?")
            let (picture, rest_of_tokens) = parsePicture name (parseExpressionList arguments) rest1
            in  _parseSyntaxTree rest_of_tokens (picture ++ pictures) drawCommands funcs

        --"<<"  -> -- Picture Function / Picture
        
        "::"  -> -- Singular Function Symbol.
            let (function, rest_of_tokens) = parseFunction name (parseExpressionList arguments) Scalar rest1
            in  _parseSyntaxTree rest_of_tokens pictures drawCommands (function:funcs)

        ":::" -> -- Vector Valued Function Symbol.
            let (function, rest_of_tokens) = parseFunction name (parseExpressionList arguments) Vector rest1
            in _parseSyntaxTree rest_of_tokens pictures drawCommands funcs

        _ -> error ("The following symbol is not understood: \"" ++ def_symbol ++"\" at " ++ debug f l c ++ " Maybe it is misplaced?")

-- Handle Draw Command.
_parseSyntaxTree tokens pictures drawCommands funcs =
    let (result, rest_of_tokens) = parseDrawCommand tokens
    in  case result of
          Just drawCommand ->
            _parseSyntaxTree rest_of_tokens pictures (drawCommand:drawCommands) funcs
          -- If we encounter a non-parsable region, then we conclude the parsing.
          -- FIXME: If we conclude the parsing, then perhaps we should have alerted an error message, instead of passing an option type back up here.
          Nothing -> _parseSyntaxTree [] pictures drawCommands funcs



-- Parses the front of a sequence of tokens into a picture and the remainder of the token list.
parsePicture :: String -> [String] -> [[String]] -> ([Picture], [[String]])
parsePicture name arguments ((basis_name:_):tokens) = 
    parseAnonymousPicture name arguments basis_name tokens [] 0

-- Labeled name -> argument names -> basis_name -> Tokens -> Pictures Parsed thus far -> index_of_anonymous_function -> (Pictures parsed, [Rest of Tokens])
parseAnonymousPicture :: String -> [String] -> String -> [[String]] -> [Picture] -> Int -> ([Picture], [[String]])

-- In this case, pictures are defined in terms of transformations on a basis.
parseAnonymousPicture name args basis_name (("[":rt):rest) pictures index =
    let (tokens, tokens_after_picture) = parseBraket (("[":rt):rest) "[" "]"
        (iterations, transform_tokens) = parseIterations tokens
        (transforms)                   = parseTransforms transform_tokens
    in
    -- Keep parsing from bottom up until we run out of picture definitions.
        case tokens_after_picture of
            (("[":rt):rest1) -> parseAnonymousPicture
                                        name
                                        args
                                        anon_name
                                        (tokens_after_picture)
                                        ((Picture {picture_name       = anon_name,
                                                   picture_arguments  = args,
                                                   picture_basis      = basis_name,
                                                   picture_transforms = transforms,
                                                   picture_iterations = iterations
                                                   }):pictures)
                                        (index + 1)
            otherwise                -> ((Picture {picture_name       = name,
                                                   picture_arguments  = args,
                                                   picture_basis      = basis_name,
                                                   picture_transforms = transforms,
                                                   picture_iterations = iterations
                                                   }):pictures,
                                        tokens_after_picture)
        where anon_name = name ++ "_" ++ (show index)

-- In this case, pictures are defined in terms of other picture functions.
parseAnonymousPicture name args basis_name (("(":rt2):rest0) pictures index =
    let (arguments, tokens_after_picture)  = parseBraket (("(":rt2):rest0) "(" ")"
        expression = basis_name ++ "(" ++ (tokensToExpression arguments) ++ ")"
    in
        -- Note: We are using the second type of picture defined by (name, expression)
        ([Direct_Picture(name, expression)]
        , tokens_after_picture)

parseAnonymousPicture name args basis_name ((_:f:l:c:[]):rest) pictures index =
    error ("Picture Parsing has failed, perhaps you are missing a leading parentheses? " ++ debug f l c)


-- Converts the front of a sequence of tokens encompassing the scope of the matched pair of left and right brakets
-- into a list of tokens within the scope, and a list of tokens that follow.
-- the output list does not contain the starting and ending brackets!
-- Tokens -> left braket -> right braket -> (parsed_tokens, rest_of_the_tokens)
parseBraket :: [[String]] -> String -> String -> ([[String]], [[String]])
-- Reduce to a helper function with a count variable.
parseBraket tokens@((first_token:f:l:c:[]):rest_of_tokens) left_braket right_braket
    | (first_token == left_braket) =
        let result = _parseBraket rest_of_tokens left_braket right_braket 1
        in
            case result of 
                Nothing -> error ("No Right Parentheses! " ++ debug f l c)
                Just something -> something

    | (first_token /= left_braket) = ([], tokens) -- The string of brakets is not present at the head of the input string of tokens.

_parseBraket :: [[String]] -> String -> String -> Int -> Maybe ([[String]], [[String]])
_parseBraket [] _ _ _ = Nothing
-- Handle left parentheses.
_parseBraket ((token:rt):rest) left_braket right_braket count
-- Left Parens.
    | token == left_braket = 
        let result = _parseBraket rest left_braket right_braket (count + 1)
        in
            case result of
                Nothing -> Nothing
                Just (output_tokens, rest_of_tokens) ->
                    Just ((token:rt):output_tokens, rest_of_tokens)
-- Right Parens.
-- We use a 1, because we want To omit the left parens.
    | (token == right_braket) && (count == 1) = Just ([], rest)
    | (token == right_braket) && (count > 1)  = -- (/=) is the not equal operator.
        let result = _parseBraket rest left_braket right_braket (count - 1)
        in
            case result of
                Nothing -> Nothing
                Just (output_tokens, rest_of_tokens) ->
                    Just ((token:rt):output_tokens, rest_of_tokens)
    | otherwise =
        let result = _parseBraket rest left_braket right_braket count
        in
            case result of
                Nothing -> Nothing
                Just (output_tokens, rest_of_tokens) ->
                    Just ((token:rt):output_tokens, rest_of_tokens)

-- Parses a function from the given name, list of arguments, and the prefix to a stream of tokens,
-- which contain the function's expression.
-- Name of function -> List of argument names, Tokens -> (Funtion, rest_of_tokens)
parseFunction :: String -> [Expression] -> Function_Type -> [[String]] -> (Function, [[String]])
-- Singleton Function.
parseFunction name arguments Scalar tokens =
    let (tokens1, rest) = parseUntilDefinition tokens
        expression     = tokensToExpression tokens1
    in (Function { function_name = name, function_arguments = arguments, function_expressions = [expression],  function_type = Scalar}, rest)


-- n-vector-valued function.
parseFunction name arguments Vector tokens =  
    let (expression_tokens, rest) = parseBraket tokens "[" "]"
        expressions = parseExpressionList expression_tokens
    in (Function { function_name = name, function_arguments = arguments, function_expressions = expressions, function_type = Vector}, rest)

-- Takes a collection of tokens and forms them into an expression.
tokensToExpression :: [Token] -> Expression
tokensToExpression [] = ""
tokensToExpression ((str:_):rest) = str ++ (tokensToExpression rest)


-- Parse the head of a list of tokens to an iteration data structure and the remainder of the tokens.
-- Tokens in -> (Iteration, The rest of the tokens.)
parseIterations :: [[String]] -> (Iteration, [[String]])
-- {i:80}
parseIterations (("{":_):(variable_name:_):(":":_):(iteration_count_str:f:l:c:[]):("}":_):rest) = 
    --let result = readMaybe iteration_count_str
    --in case result of
    --  Nothing -> error ("Iteration count in variable name was not an integer. Note: variable names are not currently supported." ++ debug f l c)
    --  Just iteration_count ->
         (Iteration {iteration_variable=variable_name, iteration_begin="0", iteration_end=(iteration_count_str)}, rest)
-- {80}
parseIterations (("{":_):(iteration_count_str:f:l:c:[]):("}":_):rest) =
    --let result = readMaybe iteration_count_str
    --in case result of
    --  Nothing -> error ("Iteration count in variable name was not an integer. Note: variable names are not currently supported." ++ debug f l c)
    --  Just iteration_count ->
            (Iteration {iteration_variable="i", iteration_begin="0", iteration_end=iteration_count_str}, rest)
parseIterations ((str:f:l:c:[]):rest) = error ("Iteration Parse Error on token \"" ++ str ++ "\" at " ++ debug f l c)

-- Converts a list of tokens into a list of transforms.
parseTransforms :: [[String]] -> [Transform]
parseTransforms [] = []
parseTransforms ((species:_):tokens) = 
    let (x, y, z, rest) = parse3List tokens "(" ")"
    in Transform { transform_species=parseTransformSpecies species, transform_x=x, transform_y=y, transform_z=z}:(parseTransforms rest)

-- Parses a list of the form [exp, exp, exp], where each exp was initially made up of tokens,
-- if left_p = "[" and right_p = "]"
-- Tokens -> (x, y, z, rest_of_tokens)
-- Tokens -> left_p -> right_p -> (x, y, z, rest_of_tokens)
-- (a, (b,c), d) --> a  (b,c)  d    --notice that the comma nested inside of parens should be ignored and not used in a split.
parse3List:: [[String]] -> String -> String -> (String, String, String, [[String]])
parse3List [] left_p right_p = error ("0 - dimensional list. 3D list expected.") -- this shouldn't really happen, this would be an erroneous call.
parse3List ((syb:rb):tokens) left_p right_p =
    let left_p == syb = True
        (tokens1, rest)  = parseBraket ((left_p:rb):tokens) left_p right_p
        result1  = parseUntilAtCurrentScope tokens1 "," left_p right_p
        f:l:c:[] = rb
        in case result1 of
            Nothing -> --error ("Perhaps you are missing a comma. " ++ debug f l c)
                -- If there is no comma, then it is a scalar and we put it into all 3 channels.
                let scalar = unwords (tokens_to_words tokens1)
                in (scalar, scalar, scalar, rest)
            Just (x_list, rest1) ->
                let
                    result2 = parseUntilAtCurrentScope rest1  "," left_p right_p
                in case result2 of
                    Nothing -> error ("Perhaps you are missing a comma. " ++ debug f l c)
                    Just (y_list, z_list) ->
                        let
                            -- http://stackoverflow.com/questions/9220986/is-there-any-haskell-function-to-concatenate-list-with-separator
                            x = unwords (tokens_to_words x_list)
                            y = unwords (tokens_to_words y_list)
                            z = unwords (tokens_to_words z_list)
                        in
                            (x, y, z, rest)
--parse3List ((name:f:l:c:[]):rest) _ _ = error ("List was not Parsed " ++ debug f l c)

-- ["a+b",  ",",  "charles",  ] -> [a+b, charles]
-- Tokens -> (list of expressions/names) -- Works on an entire list, not just a prefix.
-- Forms a list of expressions by splitting the given list of tokens at commas and then joining them.
-- the list of tokens should come preparsed without start and ending parentheses.
parseExpressionList::[[String]] -> [Expression]
parseExpressionList tokens = _parseExpressionList tokens ""

-- tokens -> accumulator -> output list.
_parseExpressionList::[[String]] -> String -> [Expression]
-- Base Case and final joined string.
_parseExpressionList [] accum = [accum]
-- Seperation.
_parseExpressionList ((",":_):rest) accum = accum:(_parseExpressionList rest "")
-- Token joining and accumulation.
_parseExpressionList ((str:_):rest)   accum = _parseExpressionList rest (accum ++ str)

-- Tokens_in -> Token searching for -> (tokens peeled off, tokens after searched for string.)
parseUntil :: [[String]] -> String -> Maybe ([[String]], [[String]])
parseUntil [] _ = Nothing
parseUntil ((name:rt):rest) search
    | name == search = Just ([], rest) -- If the name of the token matches the searched for name, we have found our partition.
    | name /= search =
        let result = parseUntil rest search
        in case result of
            Nothing -> Nothing
            Just (tokens_before, tokens_after) ->
                Just ((name:rt):tokens_before, tokens_after)

-- tokens -> token searched for -> left_p nesting start -> right_p nesting end -> output of tokens before and after the search.
parseUntilAtCurrentScope :: [[String]] -> String -> String -> String -> Maybe ([[String]], [[String]])
parseUntilAtCurrentScope tokens search left_p right_p =
    parseUntilAtCurrentScopeH tokens search left_p right_p 0

-- same, but with scope tracking variable.
parseUntilAtCurrentScopeH :: [[String]] -> String -> String -> String -> Int -> Maybe ([[String]], [[String]])
parseUntilAtCurrentScopeH [] _ _ _ _ = Nothing
parseUntilAtCurrentScopeH ((name:rt):rest) search left_p right_p scope
    -- If we are at the original scope and see the searched for value, then we are done.
    | (name == search) && (scope == 0) = Just ([], rest) -- If the name of the token matches the searched for name, we have found our partition.
    -- Otherwise, we determine the new scope variable, make a recursive call, then combine it.
    | (name /= search) || (scope /= 0) =
        let newScope =
                -- https://stackoverflow.com/questions/3479116/pattern-matching-variables-in-a-case-statement-in-haskell
                case () of 
                  ()| name == left_p  -> scope - 1
                    | name == right_p -> scope + 1
                    | otherwise       -> scope
            result = parseUntilAtCurrentScopeH rest search left_p right_p newScope
            in case result of
                Nothing -> Nothing
                Just (tokens_before, tokens_after) ->
                    Just ((name:rt):tokens_before, tokens_after)

-- Tokens_in -> (tokens peeled off, tokens starting with next definition)
-- peels off tokens until it finds tokens of the form "name <<<, name <<, name ::, name() ::/<</<<</:::, name[
-- This function allows us to Write OSKAR code like: foo(x, time) :: cos(time),
-- without putting brakets around the functional expression, by inferring where the tokens end.
-- FIXME: We may decide to just terminate scalar functions with a ';' character, it would be easier.
parseUntilDefinition :: [[String]] -> ([[String]], [[String]])
parseUntilDefinition tokens =

    --{- Parse until semi-colon.
    --(tokens, [])
    let result = parseUntil tokens ";"
    in case result of
        Nothing -> (tokens, []) -- End of file presumably, not ';' found.
        Just (left, right) -> (left, right) -- We've found it.
    --}

    {-
    let (expression, rest, Done) = _parseUntilDefinition tokens
    in (expression, rest)
    -}


-- Searches for the definition syntax symbols,
-- then moves back to exclude the definition name and potential arguments.
-- ParseState types are used to communicate the state of the move back:
--   Name -> We need to add the previous token as the name. |
--   Left_Paren, Left_Curly -> We need to add tokens until we find a left bracket. | Done
_parseUntilDefinition :: [[String]] -> ([[String]], [[String]], ParseState)
_parseUntilDefinition [] = ([], [], Done) -- End of file is ok, we simply parse the entire expression.
-- Thus far, expression will not contain curly braces.
-- They may however contain parentheses, such as 'cos(t)',
-- so we differentiate between expressions and argument lists based on a definition symbol.
_parseUntilDefinition tokens@(("{": _):rest)  = ([], tokens, Name) -- Stop at curly brace.
_parseUntilDefinition tokens@(("<<": _):rest) = ([], tokens, Name)
_parseUntilDefinition tokens@(("<<<": _):rest) = ([], tokens, Name)
_parseUntilDefinition tokens@(("::": _):rest) = ([], tokens, Name)
_parseUntilDefinition tokens@((":::": _):rest) = ([], tokens, Name)
_parseUntilDefinition tokens@(ass_token@(token: _):rest)
    | state == Done = (ass_token:out, rest, Done)  
    | state == Name && token == ")" = ([], tokens, Left_Paren) -- We can just return tokens, since it will include prefix:rest.
    | state == Name && token == "}" = ([], tokens, Left_Curly)
    | state == Name = ([], tokens, Done) -- We have come the function's name token itself.
    -- Parsing Argument lists.
    | state == Left_Paren && token /= "(" = ([], tokens, Left_Paren)
    | state == Left_Curly && token /= "{" = ([], tokens, Left_Curly)
    -- Transition back to name if we have found a left paren for an argument list.
    | state == Left_Paren && token == "(" = ([], tokens, Name)
    | state == Left_Curly && token == "{" = ([], tokens, Name)
    where (out, rest, state) = _parseUntilDefinition rest

-- Converts a list of tokens into a list of strings,
-- In other words, this removes the file:line:column metadata.
tokens_to_words :: [[String]] -> [String]
tokens_to_words [] = []
tokens_to_words ((name:_):rest) = name:(tokens_to_words rest)

tokens_to_debug_words :: [[String]] -> [String]
tokens_to_debug_words [] = []
tokens_to_debug_words ((name:f:l:c:[]):rest) = (name ++ "  " ++ f ++ "  " ++ l ++ "  " ++ c):(tokens_to_debug_words rest)

parseTransformSpecies :: String -> Transform_Species
parseTransformSpecies "*" = Scale
parseTransformSpecies "+" = Translate
parseTransformSpecies "@" = Rotate
parseTransformSpecies other = error ("ERROR: parseTransformSpecies, the token: \"" ++ other ++ "\" was not understood.")


-- Parses the front of a list of tokens
parseDrawCommand :: [[String]] -> (Maybe DrawCommand, [[String]])
parseDrawCommand ((name:_):("{":rb):rest) = 
    let (iteration, rest1)        = parseIterations (("{":rb):rest)
        (pictures, rest2)  = parseBraket rest1 "[" "]"
    in  (Just DrawCommand { drawCommand_iterations=iteration, drawCommand_pictures=tokens_to_words pictures}, rest2)
parseDrawCommand ((name:_):("[":rb):rest) =
    let iteration = Iteration { iteration_variable = "i", iteration_begin="0", iteration_end="1"}
        (pictures, rest1)  = parseBraket (("[":rb):rest) "[" "]"
    in  (Just DrawCommand { drawCommand_iterations=iteration, drawCommand_pictures=tokens_to_words pictures}, rest1)
-- No DrawCommand is present here.
parseDrawCommand tokens = (Nothing, tokens)


-- Syntax Generation Commands.

-- AST -> Header String -> output.
-- Converts an Abstract Syntax tree into a python file in the OSKAR Abstract python generation script.
generatePython :: AST -> String -> [String]
generatePython AST {ast_pictures=pictures, ast_drawings=drawCommands, ast_functions=functions} header =
    let footer = "\n# Generate Code in a Render Language\nscene.generateCode()":[]
        accum1 = generateList drawCommands generateDrawCommand footer
        accum2 = generateList pictures     generatePicture ("":accum1)
        accum3 = generateList functions    generateFunction(("# " ++(show (length(functions)))++ " functions parsed.\n"):accum2)
    in  header :
        "from pythonGenerator import *\n":
        "# Global Variables\n" :
        --"Global_t = 0\n" ++
        "scene = Scene()\n":
        accum3

-- Converts a list of arbitrary type to strings and appends it 
-- to the fron of the given input string list.
-- input list -> conversion function -> accumulation list -> output
generateList :: [a] -> (a -> String) -> [String] -> [String]
generateList (x:xs) toString accum =
    generateList xs toString ((toString x) : accum)
generateList [] _ accum = accum


generatePicture :: Picture -> String
generatePicture Picture { picture_name       = name
                         ,picture_arguments  = args
                         ,picture_basis      = basis
                         ,picture_transforms = transforms
                         ,picture_iterations = iterations
                        } =
                let indent = ""
                in
                    "# Picture definition for " ++ name ++ "\n" ++
                    --"def " ++ name ++ "():\n" ++
                    "scene.newPicture(\"" ++ name ++ "\")\n" ++
                    generateArguments args ++
                    generateIteration iterations "   " ++
                    --indent ++ "pushState()\n" ++

                     --Note: We could put a reverse(transforms) here to put the transforms in last to first order.
                     -- I like the way they are defined in OSKAR, because it is the order of matrix multiplication,
                     -- Which will be more useful to more applications.
                    generateTransforms transforms indent ++
                    --indent ++ "basis ++ "()\n" ++
                    "scene.basis(\"" ++ basis ++ "\")" ++
                    --indent ++ "popState()" ++
                    "\n"
generatePicture (Direct_Picture(name, expression)) =
    --error("Bryce should fix this soon: name = " ++ name ++ ", expression = " ++ expression)
    "# Picture via reduction for " ++ name ++ "\n" ++
    "scene.newDirectPicture(\"" ++ name ++ "\")\n" ++
    "scene.expression(\""  ++ expression ++ "\")\n"
    -- FIXME: Add arguments if necessary some day.
    -- "scene.addArgument(\""  ++ expression ++ "\")\n"
    

generateArguments :: [String] -> String
generateArguments [] = ""
generateArguments (str:rest) = "scene.addArgument(\"" ++ str ++ "\")\n" ++
    generateArguments rest

-- Iteration to be generated -> indentation string -> output.
generateIteration :: Iteration -> String -> String
generateIteration (Iteration {iteration_variable=var, iteration_begin=begin, iteration_end=end}) indent =
    {- This is the code for generating a traditional for loop.
    indent ++
    "for " ++
    var ++
    " in range(" ++
    show begin ++
    ", "  ++
    show end ++
    "):\n"
    -}
    "scene.iterations(" ++
    "\"" ++ var ++ "\"" ++
    ", " ++ 
    show begin ++
    ", " ++
    show end ++
    ")\n"

-- List of transforms to generate -> Indentation String -> output.
generateTransforms :: [Transform] -> String -> String
generateTransforms [] indentation_string = ""--indentation_string ++ "\n"
generateTransforms (Transform{transform_species = species,
                              transform_x = x,
                              transform_y = y,
                              transform_z = z}:rest)
                    indentation_string =
                    indentation_string ++
                    "scene."++ (show species) ++ "(" ++ quote x ++ ", " ++ quote y ++ ", " ++ quote z ++ ")\n" ++
                    (generateTransforms rest indentation_string)

generateDrawCommand :: DrawCommand -> String
generateDrawCommand (DrawCommand { drawCommand_iterations=iterations,
                                   drawCommand_pictures=pictureNames}) =
    let indent1 = ""
        indent2 = ""
    in
        "# Top level picture definition.\n" ++
        "scene.newDrawCommand(\"draw\")\n" ++
        (generateIteration iterations indent1) ++
        --indent2 ++ "Global_t = i\n" ++
        (generatePictureCommands pictureNames indent2)

-- function names tokens -> indentation string -> output
generatePictureCommands :: [String] -> String -> String
generatePictureCommands (name:",":rest) indent = 
    indent ++ "scene.basis(" ++
    quote name ++ ")\n" ++ (generatePictureCommands rest indent)
generatePictureCommands (name:[])       indent = 
    indent ++ "scene.basis(" ++
    quote name ++ ")\n"
generatePictureCommands [] _ = ""

generateFunction :: Function -> String
generateFunction (Function { function_name=name
                           , function_arguments=args-- symbolic variable names for the arguments that will be passed in.
                           , function_expressions=expressions -- A vector of expressions. Single valued functions will have lists of length 1.
                           , function_type=ftype
                           }) =
{- --This code directly generates Python functions.
    let indent1 = "  "
        indent2 = ""
        args_string = _argsToString args
        exp_string  =  _argsToString expressions
        (lb, rb)    = case ftype of 
                        Vector -> ("[", "]")
                        Scalar -> ("",  "")
    in
        "def " ++ name ++ "(" ++ args_string ++ "):\n" ++
        indent1 ++ "return " ++ lb ++ exp_string  ++ rb ++ "\n"
    -- FIXME: Add the rest of the function definition, determine how we will represent these functions in Python.

-- Converts an Args list into a single String.
_argsToString :: [String] -> String
_argsToString [] = ""
_argsToString (arg:[])   = arg
_argsToString (arg:rest) = arg ++ ", " ++ (_argsToString rest)
-}

-- This code generates abstract python generation language calls.
    let indent1 = "  "
        indent2 = ""
        c_name = "p = scene.newFunction(\"" ++ name ++ "\")\n"
        c_args = _argsToCommands args
        c_exps = _expressionsToCommands expressions
        c_type = _functionTypeToCommand ftype
    in
        c_name ++ c_args ++ c_exps ++ c_type


    -- FIXME: Add the rest of the function definition, determine how we will represent these functions in Python.

-- Converts an Args list into a single String.
_argsToString :: [String] -> String
_argsToString [] = ""
_argsToString (arg:[])   = arg
_argsToString (arg:rest) = arg ++ ", " ++ (_argsToString rest)

-- Converts a list of variable names into python genration language commands,
-- complete with line breaks.
_argsToCommands :: [String] -> String
_argsToCommands [] = ""
_argsToCommands (arg:rest) =
    let command = "p.addArgument(\"" ++ arg ++ "\")\n"
    in  command ++ (_argsToCommands rest)

_expressionsToCommands :: [Expression] -> String
_expressionsToCommands [] = ""
_expressionsToCommands (exp:rest) =
    let command = "p.addExpression(\"" ++ exp ++ "\")\n"
    in  command ++ (_expressionsToCommands rest)

_functionTypeToCommand :: Function_Type -> String
_functionTypeToCommand Scalar = "p.scalar_type()\n"
_functionTypeToCommand Vector = "p.vector_type()\n"
    

{-
  Utility functions.
-}

-- alternately, main = print . map readInt . words =<< readFile "test.txt"
readInt :: String -> Int
readInt = read

readIntMaybe :: String -> Maybe Int
readIntMaybe = readMaybe

error_str :: String -> String
error_str str = "!!! ERROR: " ++ str ++ " !!!\n"

debug :: String -> String -> String -> String
debug f l c = "File: " ++ f ++ ", Line: " ++ l ++", Column: " ++ c

-- Encloses the given string in quotes.
quote::String -> String
quote str = "\"" ++ str ++ "\""